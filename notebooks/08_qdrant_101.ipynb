{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qdrant 101"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![qdrant](https://qdrant.tech/images/logo_with_text.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector databases are a \"relatively\" new way for interacting with abstract data representations derived from opaque machine learning models -- deep learning architectures being the most common ones. These representations are often called vectors or embeddings and they are a compressed version of the data used to train a machine learning model to accomplish a task (e.g., sentiment analysis, speech recognition, object detection, and many more).\n",
    "\n",
    "Vector databases shine in many applications like semantic search and recommendation systems, and in these tutorial, we'll learn about how to get started with one of the most popular, and fastest growing vector databases in the market, Qdrant."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Learning Outcomes\n",
    "2. What is Qdrant?\n",
    "    - What are Vector Databases?\n",
    "    - Why do We Need Vector Databases??\n",
    "    - Overview of Qdrant's Architecture    \n",
    "    - How do We Get Started?\n",
    "3. Getting Started\n",
    "    - Adding Points\n",
    "    - Payload\n",
    "    - Search\n",
    "4. NLP & Vector Databases\n",
    "7. Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Learning Outcomes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What is Qdrant?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qdrant \"is a vector similarity search engine that provides a production-ready service with a convenient API to store, search, and manage points (i.e. vectors) with an additional payload.\" You can get started with plain python using the `qdrant-client`, pull the latest docker image of `qdrant` and connect to it locally, or try out Qdrant's Cloud free tier option until you are ready to make the full switch."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 What Are Vector Databases?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vector database is a type of database designed to store and query high-dimensional vectors efficiently. In traditional [OLTP](https://www.ibm.com/topics/oltp) and [OLAP](https://www.ibm.com/topics/olap) databases, data is organized in rows and columns, and queries are performed based on the values in those columns. However, in certain applications including image recognition, natural language processing, and recommendation systems, data is often represented as vectors in a high-dimensional space. Here is a depiction of all three next to each other.\n",
    "\n",
    "![dbs](../images/databases.png)\n",
    "\n",
    "A vector in this context is a mathematical representation of an object or data point, where each element of the vector corresponds to a specific feature or attribute of the object. For example, in an image recognition system, a vector could represent an image, with each element of the vector representing a pixel value or a descriptor/characteristic of that pixel.\n",
    "\n",
    "Vector databases are optimized for **storing** and **querying** these high-dimensional vectors efficiently, often using specialized data structures and indexing techniques such as Hierarchical Navigable Small World (HNSW), Approximate Nearest Neighbors, and Product Quantization, among others. These databases enable fast similarity and semantic search while allowing users to find vectors that are the closest to a given query vector based on some distance metric. The most commonly used distance metrics are Euclidean Distance, Cosine Similarity, and Dot Product."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Why do we need Vector Databases?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector databases play a crucial role in various applications that require similarity search, such as recommendation systems, content-based image retrieval, and personalized search. By taking advantage of their efficient indexing and searching techniques, vector databases enable faster and more accurate retrieval of similar vectors, which helps advance data analysis and decision-making.\n",
    "\n",
    "In addition, other benefits of using vector databases include:\n",
    "1. Efficient storage and indexing of high-dimensional data.\n",
    "3. Ability to handle large-scale datasets with billions or trillions of data points.\n",
    "4. Support for real-time analytics and queries.\n",
    "5. Ability to handle complex data types, such as images, videos, and natural language text.\n",
    "6. Improved performance and reduced latency in machine learning and AI applications.\n",
    "7. Reduced development and deployment time and cost compared to building a custom solution.\n",
    "\n",
    "Keep in mind that the specific benefits of using a vector database may vary depending on the use case of your organization and the features of the database."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Overview of Qdrant's Architecture (High-Level)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![qdrant](../images/qdrant_overview_high_level.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Add storage and third-party integrations to the image above"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Collections\n",
    "- Distance Metrics\n",
    "- Points\n",
    "    - id\n",
    "    - Vector\n",
    "    - Payload\n",
    "- Storage\n",
    "- Clients"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 How do we get started?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The open source version of Qdrant is available as a docker image and it can be pulled and run from any machine with docker installed. If you don't have Docker installed in your PC you can follow the instructions in the official documentation [here](https://docs.docker.com/get-docker/). After that, open your terminal start by downloading the image with the following command.\n",
    "\n",
    "```sh\n",
    "docker pull qdrant/qdrant\n",
    "```\n",
    "\n",
    "Next, initialize Qdrant with the following command, and you should be good to go.\n",
    "\n",
    "```sh\n",
    "docker run -p 6333:6333 \\\n",
    "    -v $(pwd)/qdrant_storage:/qdrant/storage \\\n",
    "    qdrant/qdrant\n",
    "```\n",
    "\n",
    "You should see something similar to the following image.\n",
    "\n",
    "![dockerqdrant](../images/docker_qdrant.png)\n",
    "\n",
    "If you experience any issues during the start process, please let us know in our [discord channel here](https://qdrant.to/discord). We are always available and happy to help.\n",
    "\n",
    "Now that you have Qdrant up and running, your next step is to pick a client to connect to it. We'll be using Python as it has the most mature data tools' ecosystem out there. Therefore, let's start setting up our dev environment and getting the libraries we'll be using today.\n",
    "\n",
    "```sh\n",
    "# with mamba or conda\n",
    "mamba env create -n my_env python=3.10\n",
    "mamba activate my_env\n",
    "\n",
    "# or with virtualenv\n",
    "python -m venv venv\n",
    "source venv/bin/activate\n",
    "\n",
    "# install packages\n",
    "pip install qdrant-client transformers datasets pandas numpy torch\n",
    "```\n",
    "\n",
    "After your have your environment ready, let's get started with Qdrant.\n",
    "\n",
    "**Note:** At the time of writing, Qdrant supports Rust, GO, Python and TypeScript. We might see other programming languages being added in the future."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Getting Started"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two modules we'll use the most are the `QdrantClient` and the `models` one. The former allows us to connect to Qdrant or it allows us to run an in-memory database by switching the parameter `host=` to `\":memory:\"` (this is a great feature for testing in a CI/CD pipeline). We'll start by instantiating our client using `host=\"localhost\"` and `port=6333` (as it is the default we used earlier with docker)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from qdrant_client.http.models import CollectionStatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(host=\"localhost\", port=6333)\n",
    "client"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In OLTP and OLAP databases we call specific bundles of rows and columns **Tables**, but in vector databases the rows are known as vectors, the columns are known as dimensions, and the combination of the two (plus some metadata) as **collections**.\n",
    "\n",
    "In the same way in which we can create many tables in a database, we can create many collections in a vector-based database using a client. The key difference to note is that when we create a collection, we need to specify the width of the collection (i.e. the length of the vector or amount of dimensions) beforehand with the parameter `size=...`, as well as the similarity metric with the parameter `distance=...` (which can be changed later on).\n",
    "\n",
    "The distances currently supported by Qdrant are:\n",
    "- Cosine Similarity\n",
    "- Dot Product\n",
    "- Euclidean Distance\n",
    "\n",
    "Let's create our first collection and have the vectors be of with 100 and the distance set to [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity). Please note that, at the time of writing, Qdrant supports cosine similarity, dot product and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_collection = \"first_collection\"\n",
    "\n",
    "first_collection = client.recreate_collection(\n",
    "    collection_name=my_collection,\n",
    "    vectors_config=models.VectorParams(size=100, distance=models.Distance.COSINE)\n",
    ")\n",
    "print(first_collection)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract information related to the health of our collection by getting the collection. In addition, we can use this information for testing purposes, which can be very beneficial while in development mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_info = client.get_collection(collection_name=my_collection)\n",
    "collection_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert collection_info.status == CollectionStatus.GREEN\n",
    "assert collection_info.vectors_count == 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a couple of things to notice from what we have done so far.\n",
    "- The first is that when we initiated our docker image, we created a local directory called, `qdrant_storage`, and this is where all of our collections, plus their metadata, will be saved at. You can have a look at that directory in a *nix system with `tree qdrant_storage -L 2`, and something similar to the following should come up for you.\n",
    "    ```bash\n",
    "    qdrant_storage\n",
    "    ├── aliases\n",
    "    │   └── data.json\n",
    "    ├── collections\n",
    "    │   └── my_first_collection\n",
    "    └── raft_state\n",
    "    ```\n",
    "- The second is that we used `client.recreate_collection` and this command, as the name implies, can be used more than once for a collection with the same name, so be careful no to recreate a collection that you did not intend to recreate. To create a brand new collection where trying to recreate another of the same name would throw an error, we would use `client.create_collection` instead.\n",
    "- Our collection can only hold vectors of 100 dimensions and the distance metric has been set to Cosine Similarity.\n",
    "\n",
    "Now that we know how to create collections, let's create a bit of fake data and add some vectors to our collection."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Adding Points"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The points are the central entity that Qdrant operates with, and these points contain records consisting of a vector, an optional id and an optional payload (which we'll talk more about in the next section).\n",
    "\n",
    "The optional id can be represented by unassigned integers or UUIDs but, for our use case, we will use  straightforward range of numbers.\n",
    "\n",
    "Let's create a matrix of fake data containing 1,000 rows and 100 columns while representing the values of our vectors as `float64` numbers between -1 and 1.\n",
    "\n",
    "For simplicity, let's imagine that each of these vectors represents one of our favorite songs, and that each columns represents a unique characteristic of the artists/bands we love, for example, the tempo, the beats, the pitch of the voice of the singer(s), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.uniform(low=-1.0, high=1.0, size=(1_000, 100))\n",
    "type(data[0, 0]), data[:2, :20]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's know create an index for our vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = list(range(len(data)))\n",
    "index[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.upsert(\n",
    "    collection_name=my_collection,\n",
    "    points=models.Batch(\n",
    "        ids=index,\n",
    "        vectors=data.tolist()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retrieve specific points based on their ID (for example, artist X with ID 1000) and get some additional information from that result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.retrieve(\n",
    "    collection_name=my_collection,\n",
    "    ids=[100],\n",
    "    with_vectors=True # we can turn this on and off depending on our needs\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also update our collection one point at a time, for example, as new data comes in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_song():\n",
    "    return np.random.uniform(low=-1.0, high=1.0, size=100).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.upsert(\n",
    "    collection_name=my_collection,\n",
    "    points=[\n",
    "        models.PointStruct(\n",
    "            id=1000,\n",
    "            vector=create_song(),\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also delete it in a straightforward fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.count(\n",
    "    collection_name=my_collection, \n",
    "    exact=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete(\n",
    "    collection_name=my_collection,\n",
    "    points_selector=models.PointIdsList(\n",
    "        points=[1000],\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.count(\n",
    "    collection_name=my_collection, \n",
    "    exact=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Payloads"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qdrant has incredible features on top of speed and reliability, and one of its most useful ones is without a doubt the ability to store additional information along with vectors. In Qdrant terminology, this information is considered a payload and it is represented as a JSON file. In addition, not only can you get this information back when you search in the database, but you can also filter your search by the parameters in the payload, and we'll see how in a second.\n",
    "\n",
    "Imagine the fake vectors we created actually represented a song. If we were building a recommender system for songs then, naturally, the things we would want to get back would be the song itself, the artist, maybe the genre, and so on.\n",
    "\n",
    "What we'll do here is to take advantage of a Python package call `faker` and create a bit of information to add to our payload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_something = Faker()\n",
    "fake_something.name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    payload.append(\n",
    "        {\n",
    "            \"artist\":   fake_something.name(),\n",
    "            \"song\":     \" \".join(fake_something.words()),\n",
    "            \"url_song\": fake_something.url(),\n",
    "            \"year\":     fake_something.year(),\n",
    "            \"country\":  fake_something.country()\n",
    "        }\n",
    "    )\n",
    "\n",
    "payload[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.upsert(\n",
    "    collection_name=my_collection,\n",
    "    points=models.Batch(\n",
    "        ids=index,\n",
    "        vectors=data.tolist(),\n",
    "        payloads=payload\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resutls = client.retrieve(\n",
    "    collection_name=my_collection,\n",
    "    ids=[10, 50, 100, 500],\n",
    "    with_vectors=False\n",
    ")\n",
    "resutls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resutls[0].payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.clear_payload(\n",
    "#     collection_name=\"my_first_collection\",\n",
    "#     points_selector=models.PointIdsList(\n",
    "#         points=index,\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our vectors with an ID and a payload, we can explore a few of ways in which we can search for content when, in our use case, new music gets selected. Let's check it out.\n",
    "\n",
    "Say, for example, that a new song comes in and our model immediately transforms it into a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "living_la_vida_loca = create_song()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.search(\n",
    "    collection_name=my_collection,\n",
    "    query_vector=living_la_vida_loca,\n",
    "    limit=10\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now imagine that we only want Australian songs recommended to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aussie_songs = models.Filter(\n",
    "    must=[models.FieldCondition(key=\"country\", match=models.MatchValue(value=\"Australia\"))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.search(\n",
    "    collection_name=my_collection,\n",
    "    query_vector=living_la_vida_loca,\n",
    "    query_filter=aussie_songs,\n",
    "    limit=5\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, say we want aussie songs but we don't care how new or old these songs are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.search(\n",
    "    collection_name=my_collection,\n",
    "    query_vector=living_la_vida_loca,\n",
    "    query_filter=aussie_songs,\n",
    "    with_payload=models.PayloadSelectorExclude(exclude=[\"year\"]),\n",
    "    limit=5\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the possibilities are endless."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. NLP & Vector Databases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common use case you will find as of today will most-likely involve language-based Generative AI models, and understandably so. Models like GPT-3, Codex, "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In NLP, vector databases are used to store word embeddings. Word embeddings are vector representations of words that capture their semantic meaning. They are used to improve the performance of NLP tasks such as text classification, machine translation, and question answering.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"ag_news\", split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dataset.features[\"label\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label\n",
    "\n",
    "num_labels = len(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2Model.from_pretrained('gpt2')#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"What does a cow use to do math? A cow-culator.\"\n",
    "em = tokenizer(text, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")#.to(device)\n",
    "em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    embs = model(**em)\n",
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs.last_hidden_state.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "\n",
    "    token_embeddings = model_output[0]\n",
    "    input_mask_expanded = (attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float())\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "def embed_text(examples):\n",
    "    inputs = tokenizer(\n",
    "        examples[\"text\"], padding=True, truncation=True, return_tensors=\"pt\"\n",
    "    )#.to(device)\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**inputs)\n",
    "    pooled_embeds = mean_pooling(model_output, inputs[\"attention_mask\"])\n",
    "    return {\"embedding\": pooled_embeds.cpu().numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_set = (\n",
    "    dataset.shuffle(42)\n",
    "           .select(range(1000))\n",
    "           .map(embed_text, batched=True, batch_size=128)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_set[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(small_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = range(len(small_set))\n",
    "small_set = small_set.add_column(\"idx\", n_rows)\n",
    "small_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_set['idx'][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_names(label_num):\n",
    "    return id2label[str(label_num)]\n",
    "\n",
    "label_names = list(map(get_names, small_set['label']))\n",
    "small_set = small_set.add_column(\"label_names\", label_names)\n",
    "small_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_size = len(small_set[0][\"embedding\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_2nd_collection = \"news_embeddings\"\n",
    "second_collection = client.recreate_collection(\n",
    "    collection_name=my_2nd_collection,\n",
    "    vectors_config=models.VectorParams(size=dim_size, distance=models.Distance.COSINE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payloads = small_set.select_columns([\"label_names\", \"text\"]).to_pandas().to_dict(orient=\"records\")\n",
    "payloads[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.upsert(\n",
    "    collection_name=my_2nd_collection,\n",
    "    points=models.Batch(\n",
    "        ids=small_set[\"idx\"],\n",
    "        vectors=small_set[\"embedding\"],\n",
    "        payloads=payloads\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = small_set[100]['embedding']\n",
    "small_set[100]['text'], query1[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.search(\n",
    "    collection_name=my_2nd_collection,\n",
    "    query_vector=query1,\n",
    "    limit=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "query2 = {\"text\": dataset[choice(range(len(dataset)))]['text']}\n",
    "query2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = embed_text(query2)['embedding'][0, :]\n",
    "query2.shape, query2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.search(\n",
    "    collection_name=my_2nd_collection,\n",
    "    query_vector=query2.tolist(),\n",
    "    limit=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business = models.Filter(\n",
    "    must=[\n",
    "        models.FieldCondition(\n",
    "            key=\"label_names\",\n",
    "            match=models.MatchValue(value=\"Business\")\n",
    "    )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.search(\n",
    "    collection_name=my_2nd_collection,\n",
    "    query_vector=query2.tolist(),\n",
    "    query_filter=business,\n",
    "    limit=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can check that our collection was indeed created with\n",
    "client.get_collections()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vdb_audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
