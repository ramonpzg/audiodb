{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69ee5d83-6229-46b8-9ca0-fbe017dccff0",
   "metadata": {},
   "source": [
    "## 05 Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718b58af-2aa9-45be-9929-0016b5407c17",
   "metadata": {},
   "source": [
    "Load up all of the libraries we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e52762bb-d190-4b93-be2c-c5c16c1c131f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForAudioClassification, AutoFeatureExtractor, TrainingArguments, Trainer, pipeline\n",
    "import evaluate\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "from faker import Faker\n",
    "from IPython.display import Audio as player\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e76612-a5d2-4315-87c6-e00742056cbd",
   "metadata": {},
   "source": [
    "Make sure you have downloaded the dataset from [Kaggle](https://www.kaggle.com/datasets/carlossalazar65/tropical-genres-dataset), and unzipped it inside the `data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb11a6ba-c66a-466a-8ce7-3b47c2d2c838",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a662b051dba4a82be9e8bc8dd1ef04c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset audiofolder (/home/ramonperez/.cache/huggingface/datasets/audiofolder/default-937056b5ef3f06eb/0.0.0/6cbdd16f8688354c63b4e2a36e1585d05de285023ee6443ffd71c4182055c0fc)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['audio', 'label'],\n",
       "    num_rows: 1500\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(path=\"audiofolder\", data_dir=\"../data/Audios/\", split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95894a17-b594-4adf-ac1d-28318af764bd",
   "metadata": {},
   "source": [
    "A few of our functions will need explicit access to the `label` variable as text and numbers, plus the amount of classes we are trying to predicts, so let's start by extracting these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f010a983-a53b-48f2-8983-d04be30375ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Bachata', 1: 'Cumbia', 2: 'Merengue', 3: 'Salsa', 4: 'Vallenato'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = dataset.features[\"label\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label\n",
    "\n",
    "num_labels = len(id2label)\n",
    "int_id_2_label = {int(k): v for k, v in id2label.items()}\n",
    "int_id_2_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9283cfe5-713d-4a0d-839a-7d7ec8d877c6",
   "metadata": {},
   "source": [
    "Since we will want to play the recommendations we receive from Qdrant, we want to load of the files (for now) rather than loading up the long piece of string that represents a sound into Qdrant. Let's get the path for each audio file using pandas, and then let's convert it to a list we'll need later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c4ae493-700c-4b87-995f-9511abe27bb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ramonperez/Tresors/datascience/challenges/qdrant_chl/data/Audios/Bachata/bachata0000.mp3',\n",
       " '/home/ramonperez/Tresors/datascience/challenges/qdrant_chl/data/Audios/Bachata/bachata0001.mp3',\n",
       " '/home/ramonperez/Tresors/datascience/challenges/qdrant_chl/data/Audios/Bachata/bachata0002.mp3',\n",
       " '/home/ramonperez/Tresors/datascience/challenges/qdrant_chl/data/Audios/Bachata/bachata0003.mp3',\n",
       " '/home/ramonperez/Tresors/datascience/challenges/qdrant_chl/data/Audios/Bachata/bachata0004.mp3']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = dataset.select_columns(\"audio\").to_pandas()['audio'].apply(lambda x: x['path']).tolist()\n",
    "paths[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3533d63-503f-4a8c-8ff2-305d002ee457",
   "metadata": {},
   "source": [
    "Time to split the data. Feel free to change the ratio used for the `test_size` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5292f96d-9bd5-4c90-8a71-b52675646f52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['audio', 'label'],\n",
       "        num_rows: 1200\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['audio', 'label'],\n",
       "        num_rows: 300\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42b40fba-0930-4370-8b7e-3e97d01f021b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio': {'path': '/home/ramonperez/Tresors/datascience/challenges/qdrant_chl/data/Audios/Cumbia/cumbia0131.mp3',\n",
       "  'array': array([ 0.        ,  0.        ,  0.        , ..., -0.26368874,\n",
       "          0.21336344,  0.684293  ], dtype=float32),\n",
       "  'sampling_rate': 44100},\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1b451d-1ff3-45a6-b003-8bfc19d8134f",
   "metadata": {},
   "source": [
    "Note that the sampling rate above is of 44,100 herts..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f117cedc-38c9-4972-9acd-6f33c8767050",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base\")\n",
    "\n",
    "def get_features(examples):\n",
    "    audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n",
    "    return feature_extractor(\n",
    "        audio_arrays, sampling_rate=feature_extractor.sampling_rate, return_tensors=\"pt\",\n",
    "        max_length=16000, truncation=True, padding=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0ecc89-2fbc-4849-9402-abf3e8e46c4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "encoded_latin = dataset.map(get_features, batched=True, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6115d07e-d7bd-4f86-844c-9fc53c18c572",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded_latin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3835aaa-a75c-4338-90c2-7e4faac2e062",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c3b6b6-9923-4d72-ac9f-bcdc6464d6a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=eval_pred.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183b859d-f86f-488b-80a6-456988b88059",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "656abd09-c4d0-4ee5-98f3-5cc3e7942823",
   "metadata": {},
   "source": [
    "## Model Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964b7994-3db1-45d4-b7a8-86edd2bc0120",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForAudioClassification.from_pretrained(\n",
    "    \"facebook/wav2vec2-base\", num_labels=num_labels, label2id=label2id, id2label=id2label\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feac730-bd65-46cc-90db-f8569735b7f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../models\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=10,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    # push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbefc09-85cf-4d55-8aa6-eef9d2f75242",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_latin[\"train\"],\n",
    "    eval_dataset=encoded_latin[\"test\"],\n",
    "    tokenizer=feature_extractor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6677e8b-2ae8-4681-b880-bf4ccb04e168",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038ec9bc-0d94-44c4-88b4-40edd1631889",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"sec_mod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5fe15c-e79e-4fa7-ba98-47fcfa1283e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"audio-classification\", model=\"sec_mod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a49958c-cffd-471b-a612-5f6f38eed126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "audio_file = dataset[\"train\"][choice(range(1000))][\"audio\"][\"path\"]\n",
    "audio_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7034660-de0a-4e59-ac85-a20ad9480689",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.predict(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa399e2-5f95-42cd-ac72-7d7d40afa77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "player(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2aeb15-911d-43d5-83cd-31f6dea21624",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3064a6-61ea-4727-a63a-4101b73f76fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = concatenate_datasets([encoded_latin['train'], encoded_latin['test']])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04839683-f58c-4b24-96e7-5e26e0827148",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "model_ckpt = \"sec_mod\"\n",
    "model = AutoModel.from_pretrained(model_ckpt).to(device)\n",
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a0e46d-2a24-449e-b177-0465909c5da9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6199557-3c93-4d00-9e06-ac78373535d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_hidden_states(batch):\n",
    "    inputs = {k: v.to(device) for k, v in batch.items() if k in feature_extractor.model_input_names}\n",
    "    with torch.no_grad():\n",
    "        last_hidden_state = model(**inputs).last_hidden_state\n",
    "    return {\"hidden_state\": last_hidden_state[:, 0].cpu().numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c111f95c-6050-4e1e-8f53-82dcdcb12b6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.set_format(\"torch\", columns=[\"label\", \"input_values\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d333a053-8f65-4719-8677-97dde3b35eb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "encoded_hidden = data.map(extract_hidden_states, batched=True, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee54660-a646-493b-829b-b7e23564e735",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "np.save('vectors_full.npy', np.array(encoded_hidden[\"hidden_state\"]), allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca949811-941f-4187-8a33-ae6ecc952f4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = encoded_hidden.rename_column(\"label\", \"genre\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4f2772-4a28-4965-ac2b-4852828c283f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "player(\n",
    "data.select_columns(['genre', 'audio']).to_pandas().head()['audio'][0][\"bytes\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d280ee9-72b4-4154-abf2-01a464b11970",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake = Faker()\n",
    "int_id_2_label = {int(k): v for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dab9425-ed68-49c7-b6fc-2fa2fde7447c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = data.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f3f1b5-a92a-4454-acc5-6ae1196c8e43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(dataset.loc[0, 'audio']['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08051e31-6909-4e11-ba16-bb7e85de8c56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset['audio_path'] = paths\n",
    "dataset[\"idx\"] = [randint(10_000, 99_999) for _ in range(len(dataset))]\n",
    "dataset[\"artist\"] = [fake.name() for _ in range(len(dataset))]\n",
    "dataset['genre'] = dataset['genre'].map(int_id_2_label)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13309987-cc9f-417f-b934-9bae79d86f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[[\"idx\", 'genre', \"artist\", 'audio_path']].to_json(\"payload.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7d1473-3767-4633-a16c-2a048469f1a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(dataset)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9ef5d2-a71f-4ce0-a383-82026567542e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.save_to_disk(\"../data/audio_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5dc3ee-b470-412d-9bd7-e891dfdbf69f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset.select_columns([\"idx\", 'genre', \"artist\", 'audio_path']).to_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e09c4a-5443-44e7-aa5f-d9b0d1c67d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from qdrant_client.http import models\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6828147-5322-46f0-9ab2-cf9925f9d17f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectors = np.load('vectors_full.npy')\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5446bf-8f15-473f-a153-159222ab4163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = QdrantClient(\"localhost\", port=6333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27daaaeb-980d-46e7-b926-accd230ad524",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "collection_info = client.get_collection(collection_name=\"test_collection\")\n",
    "collection_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d275fae-67a0-44db-90e0-309b2cc2739a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from qdrant_client.http.models import CollectionStatus\n",
    "\n",
    "assert collection_info.status == CollectionStatus.GREEN\n",
    "assert collection_info.vectors_count == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57ad41d-3493-4b25-9a54-592a446155f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.recreate_collection(\n",
    "    collection_name=\"test_collection\",\n",
    "    vectors_config=VectorParams(size=768, distance=Distance.COSINE),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb6f5a9-9032-401f-83d5-64b379a548eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = pd.read_json(\"payload.json\", orient=\"records\").set_index(\"idx\")\n",
    "payload.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d4f38f-0fc7-4c30-8a55-ee7485189d72",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# payload[['genre', 'artist', 'audio_path']]\n",
    "payload.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce0c452-e893-4693-82a2-84c3f53b183d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.upsert(\n",
    "    collection_name=\"test_collection\",\n",
    "    points=models.Batch(\n",
    "        ids=payload.index.to_list(),\n",
    "        payloads=payload.to_dict(orient=\"records\"),\n",
    "        vectors=vectors.tolist()\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653f6090-014b-4c75-85a1-020461c49997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import AudioLDMPipeline\n",
    "\n",
    "repo_id = \"cvssp/audioldm\"\n",
    "pipe = AudioLDMPipeline.from_pretrained(repo_id)\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "prompt = \"high quality bachata\"\n",
    "\n",
    "audio = pipe(prompt=prompt, num_inference_steps=20, audio_length_in_s=10.0).audios[0]\n",
    "\n",
    "from IPython.display import Audio as player\n",
    "\n",
    "player(audio, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c505f5cd-0698-48c5-93dc-06b45250aada",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"audio-classification\", model=\"sec_mod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702ff468-0036-4b7b-86fd-df6b9749bebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78da3dd-1cfd-4510-a7fc-f4d4c5efaa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"sec_mod\")\n",
    "inputs = feature_extractor(\n",
    "    audio, sampling_rate=feature_extractor.sampling_rate, \n",
    "    return_tensors=\"pt\", max_length=16000, truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758c5b3b-edc8-4418-8b8a-68c3fdc6a1e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "model = AutoModel.from_pretrained('sec_mod').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c556263-ee77-46e6-8540-b8058dfefadd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "with torch.no_grad():\n",
    "    last_hidden_state = model(**inputs.to(device)).last_hidden_state[:, 0]\n",
    "last_hidden_state.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510073cf-638e-4fe7-ae65-7b81020aa87d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectr = last_hidden_state.cpu().numpy()[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7219d5-9e99-4d26-bd0b-ed889ae0b98b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "results = client.search(\n",
    "    collection_name=\"test_collection\",\n",
    "    query_vector=vectr,\n",
    "    limit=10\n",
    ")\n",
    "results[0].payload['genre']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
